{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9章 CNNによる画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import yaml\n",
    "from pythonlibs.torch_lib_wandb import *\n",
    "print(README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイスの割り当て\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類先クラスの名称リスト\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# 分類先クラス数　今回は10になる\n",
    "n_output = len(list(set(classes)))\n",
    "# 結果確認\n",
    "print(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドロップアウトテスト用ダミーデータの作成\n",
    "torch.manual_seed(123)\n",
    "inputs = torch.randn(1, 10)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout関数の定義\n",
    "dropout = nn.Dropout(0.5)\n",
    "# 訓練フェーズでの挙動\n",
    "dropout.train()\n",
    "print(dropout.training)\n",
    "outputs = dropout(inputs)\n",
    "print(outputs)\n",
    "# 予測フェーズでの挙動\n",
    "dropout.eval()\n",
    "print(dropout.training)\n",
    "outputs = dropout(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformsの定義\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(0.5, 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得用関数 Dataset\n",
    "data_root = './data'\n",
    "train_set = datasets.CIFAR10(\n",
    "    root = data_root, train = True, \n",
    "    download = True, transform = transform)\n",
    "# 検証データの取得\n",
    "test_set = datasets.CIFAR10(\n",
    "    root = data_root, train = False, \n",
    "    download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチのサイズ指定\n",
    "batch_size = 100\n",
    "\n",
    "# 訓練用データローダー\n",
    "# 訓練用なので、シャッフルをかける\n",
    "train_loader = DataLoader(train_set, \n",
    "    batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# 検証用データローダー\n",
    "# 検証時にシャッフルは不要\n",
    "test_loader = DataLoader(test_set,  \n",
    "    batch_size = batch_size, shuffle = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の50個の表示\n",
    "show_images_labels(test_loader, classes, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_v1(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "    self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.maxpool = nn.MaxPool2d((2,2))\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.l1 = nn.Linear(6272, 128)\n",
    "    self.l2 = nn.Linear(128, n_output)\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "        self.conv1,\n",
    "        self.relu,\n",
    "        self.conv2,\n",
    "        self.relu,\n",
    "        self.maxpool)\n",
    "    \n",
    "    self.classifier = nn.Sequential(\n",
    "       self.l1,\n",
    "       self.relu,\n",
    "       self.l2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x1 = self.features(x)\n",
    "    x2 = self.flatten(x1)\n",
    "    x3 = self.classifier(x2)\n",
    "    return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_v2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.l1 = nn.Linear(4*4*128, 128)\n",
    "        self.l2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.conv4,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.conv5,\n",
    "            self.relu,\n",
    "            self.conv6,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.l1,\n",
    "            self.relu,\n",
    "            self.l2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.flatten(x1)\n",
    "        x3 = self.classifier(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測クラスの定義\n",
    "class CNN_v3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.l1 = nn.Linear(4*4*128, 128)\n",
    "        self.l2 = nn.Linear(128, num_classes)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout1,\n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.conv4,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout2,\n",
    "            self.conv5,\n",
    "            self.relu,\n",
    "            self.conv6,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout3,\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.l1,\n",
    "            self.relu,\n",
    "            self.dropout3,\n",
    "            self.l2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.flatten(x1)\n",
    "        x3 = self.classifier(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_v4(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.l1 = nn.Linear(4*4*128, 128)\n",
    "        self.l2 = nn.Linear(128, num_classes)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.conv2,\n",
    "            self.bn2,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout1,\n",
    "            self.conv3,\n",
    "            self.bn3,\n",
    "            self.relu,\n",
    "            self.conv4,\n",
    "            self.bn4,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout2,\n",
    "            self.conv5,\n",
    "            self.bn5,\n",
    "            self.relu,\n",
    "            self.conv6,\n",
    "            self.bn6,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.dropout3,\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.l1,\n",
    "            self.relu,\n",
    "            self.dropout3,\n",
    "            self.l2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.flatten(x1)\n",
    "        x3 = self.classifier(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init()\n",
    "    # 損失関数のグラフ表示\n",
    "    if wandb.config[\"Net\"] == \"CNN_v1\":\n",
    "        net = CNN_v1(n_output).to(device)\n",
    "    elif wandb.config[\"Net\"] == \"CNN_v2\":\n",
    "        net = CNN_v2(n_output).to(device)\n",
    "    elif wandb.config[\"Net\"] == \"CNN_v3\":\n",
    "        net = CNN_v3(n_output).to(device)\n",
    "    elif wandb.config[\"Net\"] == \"CNN_v4\":\n",
    "        net = CNN_v4(n_output).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #loss = eval_loss(test_loader, device, net, criterion)\n",
    "    #g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "    #display(g)\n",
    "    # 乱数の固定化\n",
    "    torch_seed()\n",
    "    # モデルインスタンス生成\n",
    "    lr = 0.01\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    num_epochs = 50\n",
    "    history = np.zeros((0, 5))\n",
    "\n",
    "    if wandb.config[\"optimizer\"] == \"SDG\":\n",
    "        # SGD\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)\n",
    "    elif wandb.config[\"optimizer\"] == \"SDG_momentum\":\n",
    "        # SGD momentum\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)\n",
    "    elif wandb.config[\"optimizer\"] == \"Adam\":\n",
    "        # Adam\n",
    "        optimizer = optim.Adam(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータ読み込み\n",
    "def yaml_read(yaml_file):\n",
    "    with open(yaml_file) as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep():\n",
    "  sweep_config = yaml_read(\"config_sweep_CNN_v.yaml\")\n",
    "  sweep_id = wandb.sweep(sweep_config, project=\"test_sweep_CNN_v\")\n",
    "  wandb.agent(sweep_id, main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
