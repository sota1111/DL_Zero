{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11章 事前学習済みモデルの利用\n",
    "- ファインチューニング：学習済みモデルのパラメータを初期値として、全てのレイヤー関数で学習する手法\n",
    "- 転移学習：学習済みモデルのうち、出力に近い部分のみ学習する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import yaml\n",
    "from pythonlibs.torch_lib_wandb import *\n",
    "print(README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイスの割り当て\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類先クラスの名称リスト\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# 分類先クラス数　今回は10になる\n",
    "n_output = len(list(set(classes)))\n",
    "# 結果確認\n",
    "print(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformsの定義\n",
    "# 学習データ用: 正規化に追加で反転とRandomErasingを実施\n",
    "transform_train = transforms.Compose([\n",
    "  transforms.Resize(112),\n",
    "  transforms.RandomHorizontalFlip(p=0.5), \n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(0.5, 0.5), \n",
    "  transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "])\n",
    "# 検証データ用 : 正規化のみ実施\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize(112),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(0.5, 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得用関数 Dataset\n",
    "data_root = './data'\n",
    "train_set = datasets.CIFAR10(\n",
    "    root = data_root, train = True,\n",
    "    download = False, transform = transform_train)\n",
    "# 検証データの取得\n",
    "test_set = datasets.CIFAR10(\n",
    "    root = data_root, train = False, \n",
    "    download = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ指定\n",
    "batch_size = 50\n",
    "# データローダー\n",
    "# 訓練用データローダー\n",
    "# 訓練用なので、シャッフルをかける\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# 検証用データローダー\n",
    "# 検証時にシャッフルは不要\n",
    "test_loader = DataLoader(test_set,  batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  必要ライブラリのロード\n",
    "from torchvision import models\n",
    "# 事前学習済みモデルのロード\n",
    "# pretraind = True で学習済みパラメータも一緒に読み込む\n",
    "net = models.resnet18(pretrained = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークの概要表示\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのサマリー表示\n",
    "net = net.to(device)\n",
    "#summary(net,(100,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.fc)\n",
    "print(net.fc.in_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最終レイヤー関数の付け替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数の初期化\n",
    "torch_seed()\n",
    "# 最終レイヤー関数の入力次元数を確認\n",
    "fc_in_features = net.fc.in_features\n",
    "# 最終レイヤー関数の付け替え\n",
    "net.fc = nn.Linear(fc_in_features, n_output)\n",
    "# 確認\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "#summary(net,(100,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失の計算グラフ可視化\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = eval_loss(test_loader, device, net, criterion)\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "#display(g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習と結果評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数の初期化\n",
    "torch_seed()\n",
    "\n",
    "# 事前学習済みモデルのロード\n",
    "# pretraind = True で学習済みパラメータも一緒に読み込む\n",
    "net = models.resnet18(pretrained = True)\n",
    "\n",
    "# 最終レイヤー関数の入力次元数を確認\n",
    "fc_in_features = net.fc.in_features\n",
    "\n",
    "# 最終レイヤー関数の付け替え\n",
    "net.fc = nn.Linear(fc_in_features, n_output)\n",
    "\n",
    "# GPUの利用\n",
    "net = net.to(device)\n",
    "\n",
    "# 学習率\n",
    "lr = 0.001\n",
    "\n",
    "# 損失関数定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化関数定義\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# historyファイル初期化する\n",
    "history = np.zeros((0, 5))\n",
    "\n",
    "# 学習\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init()\n",
    "    # 乱数の初期化\n",
    "    torch_seed()\n",
    "    # 事前学習済みモデルのロード\n",
    "    # pretraind = True で学習済みパラメータも一緒に読み込む\n",
    "    net = models.resnet18(pretrained = True)\n",
    "    # 最終レイヤー関数の入力次元数を確認\n",
    "    fc_in_features = net.fc.in_features\n",
    "    # 最終レイヤー関数の付け替え\n",
    "    net.fc = nn.Linear(fc_in_features, n_output)\n",
    "    # GPUの利用\n",
    "    net = net.to(device)\n",
    "    # 学習率\n",
    "    lr = 0.001\n",
    "    # 損失関数定義\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # historyファイル初期化する\n",
    "    history = np.zeros((0, 5))\n",
    "    num_epochs = 20\n",
    "\n",
    "    if wandb.config[\"optimizer\"] == \"SDG\":\n",
    "        # SGD\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"SDG_momentum\":\n",
    "        # SGD momentum\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"Adagrad\":\n",
    "        # Adagrad\n",
    "        optimizer = optim.Adagrad(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"Adam\":\n",
    "        # Adam\n",
    "        optimizer = optim.Adam(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"RMSprop\":\n",
    "        # RMSprop\n",
    "        optimizer = optim.RMSprop(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"Adadelta\":\n",
    "        # Adadelta\n",
    "        optimizer = optim.Adadelta(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    elif wandb.config[\"optimizer\"] == \"AdamW\":\n",
    "        # AdamW\n",
    "        optimizer = optim.AdamW(net.parameters())\n",
    "        history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, use_wandb=True)\n",
    "    \n",
    "    print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータ読み込み\n",
    "def yaml_read(yaml_file):\n",
    "    with open(yaml_file) as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep():\n",
    "  sweep_config = yaml_read(\"config_sweep_trans.yaml\")\n",
    "  sweep_id = wandb.sweep(sweep_config, project=\"saitan_sweep_trans\")\n",
    "  wandb.agent(sweep_id, main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
