{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Zero4_2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNIBS0rX64d5FYIwn5BNY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sota1111/DL_Zero4/blob/main/DL_Zero4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy matplotlib ipython scikit-learn pandas pillow dezero gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cmQYz1zfyxd",
        "outputId": "32aac832-5a92-4a74-9b73-b684d063a985"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: dezero in /usr/local/lib/python3.7/dist-packages (0.0.13)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython) (0.2.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiYUdUWugGMo",
        "outputId": "85f62340-bed6-4d4c-eeea-82cae4ad13ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [C\u001b[0m\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [C\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "26 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "d = Display()\n",
        "d.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-1PwcAdgH2U",
        "outputId": "f57a3e32-3845-4990-9ae8-0f2c3ef55b2a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f71b6e78610>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update && apt install xvfb\n",
        "!pip install gym-notebook-wrapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOayo_6ah78F",
        "outputId": "8b1977bc-c58c-42f0-c35e-618d7904cfb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to cloud.r-project.org (52.85.151.129)] [Co\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to developer.download.nvidia.com (152.195.1\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to developer.dow\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "26 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym-notebook-wrapper in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (5.5.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (0.17.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-notebook-wrapper) (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gym-notebook-wrapper) (4.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->gym-notebook-wrapper) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8章 DQN\n",
        "DQN：Q学習とニューラルネットワークを使った手法。  \n",
        "前章から「経験再生」と「ターゲットネットワーク」が使われる。  "
      ],
      "metadata": {
        "id": "ABnEh0KblZ9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 OpenAI Gym"
      ],
      "metadata": {
        "id": "hz6CHGGYmgm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.1 OpenAI Gymの基礎知識"
      ],
      "metadata": {
        "id": "hKERA4XrldYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('CartPole-v0')\n",
        "\n",
        "state = env.reset()\n",
        "print(state)\n",
        "\n",
        "action_space = env.action_space\n",
        "print(action_space)"
      ],
      "metadata": {
        "id": "SOv5rdCclgW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5cc2f9-c691-4603-c241-7493802c0cea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01500541 -0.04675612  0.02819637  0.03702204]\n",
            "Discrete(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = 0\n",
        "next_state, reward, done, info = env.step(action)\n",
        "print(next_state)"
      ],
      "metadata": {
        "id": "O0WFV-eklj9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9fe139-ecb6-45f8-8d53-1ab489925e10"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01594053 -0.24227082  0.02893681  0.33846616]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.2 ランダムなエージェント"
      ],
      "metadata": {
        "id": "yX6p-bVVlylp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gnwrapper\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "env_gnw = gnwrapper.Animation(env) # Xvfbが起動される\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  env_gnw.render() # ここで、前の描画を消し、新しいステップの描画を行う。\n",
        "  action = np.random.choice([0, 1])\n",
        "  next_state, reward, done, info = env.step(action) # 本当はDNNからアクションを入れる\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "gBs14lvJhrNY",
        "outputId": "192ab3ec-deb3-4958-98b5-ce93987de1c9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAADnCAYAAABBu67aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAInElEQVR4nO3dzW8chRnA4Xd212s7dj4aJ3GAkJICIqGQNFRCVRsq9cAZ9UKVSvwZnPgTOPXUe2+9cGoPcEAtSlqQgJZCrUKbBpoI0iYhIbYTf+zu9EDV4owV28lLZiZ9nptfr+X3sPppdmdntijLMgC4c526FwC4VwgqQBJBBUgiqABJBBUgSW+D3/sIAEBVsd7QESpAEkEFSCKoAEkEFSCJoAIkEVSAJIIKkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJBFUgCSCCpBEUAGSCCpAEkEFSCKoAEkEFSCJoAIkEVSAJIIKkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJBFUgCSCCpBEUAGSCCpAEkEFSCKoAEkEFSCJoAIkEVSAJIIKkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJBFUgCSCCpBEUAGSCCpAEkEFSCKoAEkEFSCJoAIkEVSAJIIKkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJOnVvQBsxXDlRizPX45OtxfjO2ejKIq6V4L/ElRaZf7TD+PMaz+Pbn8ydh48GlFETO09FHsf/2EUnW7d6/F/TlBpjbIsYzRYjYgvj1Q//9tbERFx5czbsePA4zGxa7bO9cB7qLRIWcaF916tjCd23Rfd8ckaFoK1BJVWGQ1WKrOp2UMxNrmjhm1gLUGlNVavX103qNAUgkprfHHug1hdvLJmVnTHYubR79W0EawlqLRaUXRifMe+uteAiBBUWmI0HMS183OVedHtRfgsKg0hqLRCORrGwoUzlfneI89Eb2K6ho2gSlBptaI75mopGkNQaYXP//pmDJYW1syKTi/Gt8/UtBFUCSqtsHrjWkQ5WjPrjm+LXYeeqmkjqBJUGq8cjWK4cqPuNWBDgkrjDZbm49JfTlfmOx/8dnS6bkdBcwgq7XDTy/2IiKnZh91hikYRVBrv+uXzUY6qQXV2n6YRVBrv6tl3oxwN1sz622di5zeP1bQRrE9QaaVOdyx6E1N1rwFrCCqNtrJ4NeY//agy746LKc0jqDTaaHUplucvVuazR5+NCO+h0iyCSqOVo1FEWZ0XRcdJKRpHUGm0f/7ptbi5qL2J6ehPf6OeheAWBJVGGyxfr8zGd87Gtj0Ha9gGbk1Qaazh6rJLTmkVQaWxblw+HwufVc/w737k6Rq2gY0JKq2zbebBuleAdQkqjTW/ztFpROErT2gsQaWxvvjH+5XZjgNHYtseR6g0k6DSKkV3LDrdsbrXgHUJKo20cOFMLF35tDLvT/n8Kc0lqDTSYGmh+pGpooh9T/yonoVgEwSVxinLMkaDlbrXgC0TVBqojAvvvVqZTu4+4C5TNJqg0jxlRDlcrYyn9j4UY5Pba1gINkdQaZyVxSsxXF2uew3YMkGlca6dn4vVxStrZkW3FzOPfb+mjWBzBJVWKIpOjG+fqXsNuCVBpVFGw8G6V0h1en2XnNJ4gkqjlKNhLP7rbGW+5/CJ6E04IUWzCSqtUHR7vvKExhNUGuXyR7+PwdLCmlnR6cX49j01bQSbJ6g0ymBpIaIcrZl1x7fFrkNP1bQRbJ6g0hjlaBTDdb5DCtpCUGmMwdJCXPrwVGW+8+CT0en2atgItkZQaZayrIym9h2KotOtYRnYGkGlQaoxhTYRVBrj4txvYzRYe1OUTm88+tNuKk07CCqNsXrjWtx8lDo2tSt2PPB4PQvBFgkqjTAaDmK4slT3GnBHBJVGWJm/FFf+/k5lvuuh77iGn9YQVBqkelJqevZbLjmlNQSVRli8+ImT/LSeoNIIV8++GzcXdXLmQGy//7F6FoLbIKg0VqfXj87YRN1rwKYJKrVbunph3Xuguv8pbSOo1G6wvBir17+ozGePPuuEFK0iqNSuHA3XnYspbSOo1O7CH1+tzPrTu6M3uaOGbeD2CSq1G61Wr5CanDkQEzv31bAN3D5BpVaD5UWXnHLPKMp17j/5FT5qzZa99NJLMTc3t6nHPrqvHz/57q41s9GojJ/96s+xOLbxEerJkyfj+eefv6094Q6s+wa/26CT7tSpU/HGG29s6rHPHD0YPz7+XJTlly+WusVqFLESp9+Zi48v/G7Dvz9+/Pgd7QqZBJVaHXnkyTh96blYGk1FRMRM/7N4cvq12OCVEzSSoFKboihi4v6fxuLwfy/5Ly4/EL98/0acv3itxs3g9jgpRa0Go7E1P5fRjU/mD8Rw5AiV9hFUavODJw7Gw7M3DcvV6C+9Xcs+cKcEldr0xzqxf/jrWLzyfhSDizHVvRr7xz6I1988XfdqcFu8h0ptXn/3bPzmDx9HGb+Ip48ciPtmtsdwOIzrSzfqXg1uyy2D+vLLL9+tPbiHnDt3btOPHf3nbP5bc5v/m686ffq05yl33Ysvvrju/JZBfeGFF76WZbi3vfLKK3H2bPV2fF+HY8eOeZ7SGLcM6v79++/WHtxD+v3+Xftf09PTnqc0hpNSAEkEFSCJoAIkEVSAJIIKkMQH+0l34sSJ2L179135X4cPH74r/wc2ww2mAbZu3RtMe8kPkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJBFUgCSCCpBEUAGSCCpAEkEFSCKoAEkEFSCJoAIkEVSAJIIKkERQAZIIKkASQQVIIqgASQQVIImgAiQRVIAkggqQRFABkggqQBJBBUgiqABJBBUgiaACJBFUgCSCCpBEUAGSCCpAEkEFSCKoAEl6G/y+uCtbANwDHKECJBFUgCSCCpBEUAGSCCpAEkEFSPJvZ4KIxyV2CXoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2 DQNのコア技術\n",
        "DQNはニューラルネットワークの学習を安定させるために、経験再生とターゲットネットワークという技術を使う。"
      ],
      "metadata": {
        "id": "M-VV0EbFToa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.1 経験再生\n",
        "エージェントが経験したデータをバッファに保存し、Q関数を更新する際には、そのバッファから経験データをランダムに取り出して使う。  \n",
        "経験再生によって、経験データ間の相関が弱まり、偏りの少ないデータが得られる。さらに、経験データを繰り返し使うことができるため、データ効率が良くなる。"
      ],
      "metadata": {
        "id": "wXRAiz5QTodm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.2 経験再生の実装"
      ],
      "metadata": {
        "id": "feLXnzPBTogV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class ReplayBuffer:\n",
        "  def __init__(self, buffer_size, batch_size):\n",
        "    self.buffer = deque(maxlen=buffer_size)\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def add(self, state, action, reward, next_state, done):\n",
        "    data = (state, action, reward, next_state, done)\n",
        "    self.buffer.append(data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n",
        "  \n",
        "  def get_batch(self):\n",
        "    data = random.sample(self.buffer, self.batch_size)\n",
        "\n",
        "    state = np.stack([x[0] for x in data])\n",
        "    action = np.array([x[1] for x in data])\n",
        "    reward = np.array([x[2] for x in data])\n",
        "    next_stage = np.array([x[3] for x in data])\n",
        "    done = np.array([x[4] for x in data]).astype(np.int32)\n",
        "    return state, action, reward, next_state, done\n"
      ],
      "metadata": {
        "id": "196fnf_gVhWn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "replay_buffer = ReplayBuffer(buffer_size=10000, batch_size=32)\n",
        "\n",
        "for episode in range(10):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "\n",
        "  while not done:\n",
        "    action = 0\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    replay_buffer.add(state, action, reward, next_state, done)\n",
        "    state = next_state\n",
        "\n",
        "state, action, reward, next_state, done = replay_buffer.get_batch()\n",
        "print(state.shape)\n",
        "print(action.shape)\n",
        "print(reward.shape)\n",
        "print(next_state.shape)\n",
        "print(done.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcgsLP2EXaeG",
        "outputId": "2b1b2adb-d5b3-4f66-ba81-07f92d4a4fd0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 4)\n",
            "(32,)\n",
            "(32,)\n",
            "(4,)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.1 ターゲットネットワーク\n",
        "Q学習では、Q (St、At)の値がRt+r*maxQ(St+1, α)：TDターゲット　  \n",
        "となるようにQ関数を更新する。TDターゲットの値は、Q関数が更新されると変動する。これを固定する。  \n",
        "オリジナルのネットワークqnetと同じ構造のネットワークqnet_targetを用意し、定期的にqnetの重みと同期するようにして、それ以外は重みパラメータを固定する。  \n",
        "qnet_targetを使って、TDターゲットの値を計算すれば、教師レベルであるTDターゲットの変動が抑えられる。これにより、TDターゲットが（常には）変動しないので、ニューラルネットワークの学習が安定することが期待される。"
      ],
      "metadata": {
        "id": "6AQRRDcsaAWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.4 ターゲットネットワークの実装\n"
      ],
      "metadata": {
        "id": "Uicxud_oZ4A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from dezero import Model\n",
        "from dezero import optimizers\n",
        "import dezero.functions as F\n",
        "import dezero.layers as L\n",
        "\n",
        "class QNet(Model):\n",
        "  def __init__(self, action_size):\n",
        "    super().__init__()\n",
        "    self.l1 = L.Linear(128)\n",
        "    self.l2 = L.Linear(128)\n",
        "    self.l3 = L.Linear(action_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.l1(x))\n",
        "    x = F.relu(self.l2(x))\n",
        "    x = self.l3(x)\n",
        "    return x\n",
        "\n",
        "class DQNAgent:\n",
        "  def __init__(self):\n",
        "    self.gamma = 0.98\n",
        "    self.lr = 0.0005\n",
        "    self.epsilon = 0.1\n",
        "    self.buffer_size = 10000\n",
        "    self.batch_size = 32\n",
        "    self.action_size = 2\n",
        "\n",
        "    self.replay_buffer = ReplayBuffer(self.buffer_size, self.batch_size)\n",
        "    self.qnet = QNet(self.action_size)\n",
        "    self.qnet_target = QNet(self.action_size)\n",
        "    self.optimizer = optimizers.Adam(self.lr)\n",
        "    self.optimizer.setup(self.qnet)#qnetを設定\n",
        "\n",
        "  def sync_qnet(self):\n",
        "    self.qnet_target = copy.deepcopy(self.qnet)\n",
        "\n",
        "  def get_action(self, state):\n",
        "    if np.random.rand() < self.epsilon:\n",
        "      return np.random.choice(self.action_size)\n",
        "    else:\n",
        "      state = state[np.newaxis, :]\n",
        "      qs = self.qnet(state)\n",
        "      return qs.data.argmax()\n",
        "\n",
        "  def update(self, state, action, reward, next_state, done):\n",
        "    self.replay_buffer.add(state, action, reward, next_state, done)\n",
        "    if len(self.replay_buffer) < self.batch_size:\n",
        "      return\n",
        "\n",
        "    state, action, reward, next_state, done = self.replay_buffer.get_batch()\n",
        "    qs = self.qnet(state)#①\n",
        "    q = qs[np.arange(self.batch_size), action]#②\n",
        "\n",
        "    next_qs = self.qnet_target(next_state)#③\n",
        "    next_q = next_qs.max(axis=1)\n",
        "    next_q.unchain()\n",
        "    target = reward + (1 - done) * self.gamma * next_q#④\n",
        "\n",
        "    loss = F.mean_squared_error(q, target)\n",
        "\n",
        "    self.qnet.cleargrads()\n",
        "    loss.backward()\n",
        "    self.optimizer.update()"
      ],
      "metadata": {
        "id": "-TYfjRy4Z9AW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.5 DQNを動かす"
      ],
      "metadata": {
        "id": "tv-G1JuMs8J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 300\n",
        "sync_interval = 20\n",
        "env = gym.make('CartPole-v0')\n",
        "agent = DQNAgent()\n",
        "reward_histrory = []\n",
        "\n",
        "for episode in range(episodes):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "\n",
        "  while not done:\n",
        "    action = agent.get_action(state)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "\n",
        "    agent.update(state, action, reward, next_state, done)\n",
        "    state = next_state\n",
        "    total_reward += reward\n",
        "\n",
        "  if episode % sync_interval == 0:\n",
        "    agent.sync_qnet()\n",
        "\n",
        "  reward_histrory.append(total_reward)"
      ],
      "metadata": {
        "id": "v-JcLW6-juJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "5dd50ff9-f3ce-4eec-893d-9ccec98e2a17"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cc2abb744dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-8f77f87683b4>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mnext_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnet_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#③\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mnext_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_qs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mnext_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_q\u001b[0m\u001b[0;31m#④\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dezero/functions.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dezero/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dezero/functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     38\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     39\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eH2MF-3YvA_7"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}